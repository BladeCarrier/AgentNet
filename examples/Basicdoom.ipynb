{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [this demo requires doom installed either officially or from gym-pool. Or simply use https://github.com/justheuristic/doomed_dqn]\n",
    "\n",
    "# This tutorial is will bring you through your first deep reinforcement learning model\n",
    "\n",
    "\n",
    "* Seaquest game as an example\n",
    "* Training a simple lasagne neural network for Q_learning objective\n",
    "\n",
    "\n",
    "## About OpenAI Gym\n",
    "\n",
    "* Its a recently published platform that basicly allows you to train agents in a wide variety of environments with near-identical interface.\n",
    "* This is twice as awesome since now we don't need to write a new wrapper for every game\n",
    "* Go check it out!\n",
    "  * Blog post - https://openai.com/blog/openai-gym-beta/\n",
    "  * Github - https://github.com/openai/gym\n",
    "\n",
    "\n",
    "## New to Lasagne and AgentNet?\n",
    "* We only require surface level knowledge of theano and lasagne, so you can just learn them as you go.\n",
    "* Alternatively, you can find Lasagne tutorials here:\n",
    " * Official mnist example: http://lasagne.readthedocs.io/en/latest/user/tutorial.html\n",
    " * From scratch: https://github.com/ddtm/dl-course/tree/master/Seminar4\n",
    " * From theano: https://github.com/craffel/Lasagne-tutorial/blob/master/examples/tutorial.ipynb\n",
    "* This is pretty much the basic tutorial for AgentNet, so it's okay not to know it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"device=gpu\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%env THEANO_FLAGS=\"device=gpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imresize\n",
    "#game image will be resized from(96,128) to your image_size. \n",
    "#You may want a bigger image for your homework assignment IF you want a larger NN\n",
    "\n",
    "IMAGE_W,IMAGE_H = IMAGE_SIZE =(60,80)#(96,128)\n",
    "def preprocess(obs):\n",
    "    return (imresize(obs,IMAGE_SIZE).mean(-1)/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:42:08,087] Making new env: ppaquette/DoomBasic-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ppaquette_gym_doom\n",
    "from gym.wrappers import SkipWrapper\n",
    "from ppaquette_gym_doom.wrappers.action_space import ToDiscrete\n",
    "GAME_NAME = 'ppaquette/DoomBasic-v0'\n",
    "\n",
    "make_env = lambda: SkipWrapper(4)(ToDiscrete(\"minimal\")(gym.make(GAME_NAME)))\n",
    "\n",
    "env = make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global params.\n",
    "\n",
    "#number of parallel agents and batch sequence length (frames)\n",
    "N_AGENTS = 1\n",
    "SEQ_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.0 False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1bab447bd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcgAAAFhCAYAAAD0sjrMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1bac53b690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "obs,r,done,_=env.step(1)\n",
    "print r, done\n",
    "plt.imshow(preprocess(obs),cmap='gray',interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using simple convolutional neural network.\n",
    "\n",
    "![scheme](https://s18.postimg.org/gbmsq6gmx/dqn_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is enabled with initial size: 45.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "#image observation at current tick goes here, shape = (sample_i,x,y,color)\n",
    "observation_layer = InputLayer((None,IMAGE_W,IMAGE_H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.memory import WindowAugmentation,LSTMCell,RNNCell\n",
    "\n",
    "#store 4-tick window in order to perceive motion of objects\n",
    "\n",
    "prev_window = InputLayer((None,4,IMAGE_W,IMAGE_H))\n",
    "\n",
    "current_window = WindowAugmentation(observation_layer,prev_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import Conv2DLayer,Pool2DLayer,DenseLayer,batch_norm,dropout\n",
    "\n",
    "#main neural network body\n",
    "conv0 = Conv2DLayer(current_window,32,filter_size=(8,8),stride=(4,4),name='conv0')\n",
    "\n",
    "conv1 = Conv2DLayer(batch_norm(conv0),64,filter_size=(4,4),stride=(2,2),name='conv1')\n",
    "\n",
    "dense0 = DenseLayer(batch_norm(conv1),512,name='dense',nonlinearity = lasagne.nonlinearities.tanh)\n",
    "\n",
    "#please set this to your last layer for convenience\n",
    "last_layer = dense0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a layer that predicts Qvalues\n",
    "qvalues_layer = DenseLayer(last_layer,\n",
    "                   num_units = env.action_space.n,\n",
    "                   nonlinearity=lasagne.nonlinearities.linear,\n",
    "                   name=\"q-evaluator layer\")\n",
    "\n",
    "#To pick actions, we use an epsilon-greedy resolver (epsilon is a property)\n",
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer,name=\"e-greedy action picker\")\n",
    "\n",
    "action_layer.epsilon.set_value(np.float32(0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.target_network import TargetNetwork\n",
    "targetnet = TargetNetwork(qvalues_layer,dense0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qvalues_old = targetnet.output_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              policy_estimators=(qvalues_layer,qvalues_old),\n",
    "              agent_states={current_window:prev_window},\n",
    "              action_layers=action_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[conv0.W,\n",
       " conv0_bn.beta,\n",
       " conv0_bn.gamma,\n",
       " conv1.W,\n",
       " conv1_bn.beta,\n",
       " conv1_bn.gamma,\n",
       " dense.W,\n",
       " dense.b,\n",
       " q-evaluator layer.W,\n",
       " q-evaluator layer.b]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:43:14,948] Making new env: ppaquette/DoomBasic-v0\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "\n",
    "pool = EnvPool(agent,make_env, \n",
    "               preprocess_observation=preprocess,\n",
    "               n_games=N_AGENTS,max_size=1000) #may need to adjust for speed/memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2 3 3 3 1 0]]\n",
      "[[ -5.  -5.  -5.  -5.  -5. -10.   0.]]\n",
      "CPU times: user 64 ms, sys: 4 ms, total: 68 ms\n",
      "Wall time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "_,action_log,reward_log,_,_,_  = pool.interact(7)\n",
    "\n",
    "\n",
    "print(action_log[:2])\n",
    "print(reward_log[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load first sessions (this function calls interact and remembers sessions)\n",
    "pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning\n",
    "* An agent has a method that produces symbolic environment interaction sessions\n",
    "* Such sessions are in sequences of observations, agent memory, actions, q-values,etc\n",
    "  * one has to pre-define maximum session length.\n",
    "\n",
    "* SessionPool also stores rewards (Q-learning objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100,replace=True)\n",
    "\n",
    "_,_,_,_,(qvalues_seq,old_qvalues_seq) = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get reference Qvalues according to Qlearning algorithm\n",
    "from agentnet.learning import qlearning\n",
    "\n",
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      qvalues_target=old_qvalues_seq,\n",
    "                                                      gamma_or_gammas=0.99,)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "updates = lasagne.updates.adam(loss,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:46:55,554] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:46:55,569] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:46:55,571] Clearing 4 monitor files from previous run (because force=True was provided)\n",
      "[2017-01-14 11:46:55,893] Starting new video recorder writing to /home/hedgedir/agentnet/examples/records/openaigym.video.1.2042.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 70 timesteps with reward=-385.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:46:58,043] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    }
   ],
   "source": [
    "action_layer.epsilon.set_value(0)\n",
    "untrained_reward = pool.evaluate(save_path=\"./records\",record_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"records/openaigym.video.94.4407.video000000.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "video_path=\"<paste path to video here, starting from ./records/>\"\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "\n",
    "#full game rewards\n",
    "rewards = {epoch_counter:untrained_reward}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=10\tepsilon=0.954\treward/step=-4.17273\n",
      "iter=20\tepsilon=0.910\treward/step=-3.62381\n",
      "iter=30\tepsilon=0.868\treward/step=-3.82258\n",
      "iter=40\tepsilon=0.828\treward/step=-3.45122\n",
      "iter=50\tepsilon=0.790\treward/step=-3.81373\n",
      "iter=60\tepsilon=0.754\treward/step=-4.07377\n",
      "iter=70\tepsilon=0.719\treward/step=-4.06197\n",
      "iter=80\tepsilon=0.687\treward/step=-3.68889\n",
      "iter=90\tepsilon=0.656\treward/step=-3.87692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:47:29,611] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:47:29,618] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:47:29,620] Clearing 4 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=100\tepsilon=0.626\treward/step=-3.97327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:47:31,281] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 70 timesteps with reward=-395.0\n",
      "iter=110\tepsilon=0.598\treward/step=-4.09279\n",
      "iter=120\tepsilon=0.571\treward/step=-4.00909\n",
      "iter=130\tepsilon=0.546\treward/step=-4.09237\n",
      "iter=140\tepsilon=0.522\treward/step=-4.09220\n",
      "iter=150\tepsilon=0.499\treward/step=-4.16225\n",
      "iter=160\tepsilon=0.477\treward/step=-4.01056\n",
      "iter=170\tepsilon=0.456\treward/step=-3.96199\n",
      "iter=180\tepsilon=0.436\treward/step=-3.61436\n",
      "iter=190\tepsilon=0.417\treward/step=-3.58063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:48:00,677] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:48:00,686] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:48:00,687] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=200\tepsilon=0.399\treward/step=-3.60846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:48:01,279] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 12 timesteps with reward=36.0\n",
      "iter=210\tepsilon=0.382\treward/step=-3.66967\n",
      "iter=220\tepsilon=0.366\treward/step=-3.72986\n",
      "iter=230\tepsilon=0.351\treward/step=-3.60130\n",
      "iter=240\tepsilon=0.336\treward/step=-3.53568\n",
      "iter=250\tepsilon=0.322\treward/step=-3.46932\n",
      "iter=260\tepsilon=0.309\treward/step=-3.43716\n",
      "iter=270\tepsilon=0.296\treward/step=-3.29557\n",
      "iter=280\tepsilon=0.284\treward/step=-3.04698\n",
      "iter=290\tepsilon=0.273\treward/step=-2.85292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:48:34,420] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:48:34,431] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:48:34,432] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=300\tepsilon=0.262\treward/step=-2.70897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:48:34,800] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 3 timesteps with reward=86.0\n",
      "iter=310\tepsilon=0.252\treward/step=-2.56785\n",
      "iter=320\tepsilon=0.242\treward/step=-2.34424\n",
      "iter=330\tepsilon=0.232\treward/step=-2.09335\n",
      "iter=340\tepsilon=0.224\treward/step=-1.95894\n",
      "iter=350\tepsilon=0.215\treward/step=-1.94929\n",
      "iter=360\tepsilon=0.207\treward/step=-1.73269\n",
      "iter=370\tepsilon=0.199\treward/step=-1.49892\n",
      "iter=380\tepsilon=0.192\treward/step=-1.33360\n",
      "iter=390\tepsilon=0.185\treward/step=-1.03990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:49:11,841] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:49:11,851] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:49:11,853] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=400\tepsilon=0.179\treward/step=-0.89451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:49:12,534] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 16 timesteps with reward=6.0\n",
      "iter=410\tepsilon=0.172\treward/step=-0.44063\n",
      "iter=420\tepsilon=0.166\treward/step=-0.24228\n",
      "iter=430\tepsilon=0.161\treward/step=0.04919\n",
      "iter=440\tepsilon=0.155\treward/step=0.30567\n",
      "iter=450\tepsilon=0.150\treward/step=0.50155\n",
      "iter=460\tepsilon=0.145\treward/step=0.71302\n",
      "iter=470\tepsilon=0.141\treward/step=0.98280\n",
      "iter=480\tepsilon=0.136\treward/step=1.17131\n",
      "iter=490\tepsilon=0.132\treward/step=1.39878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:49:52,861] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:49:52,869] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:49:52,870] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=500\tepsilon=0.128\treward/step=1.61776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:49:53,275] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 3 timesteps with reward=86.0\n",
      "iter=510\tepsilon=0.124\treward/step=1.86947\n",
      "iter=520\tepsilon=0.121\treward/step=2.07102\n",
      "iter=530\tepsilon=0.117\treward/step=2.24670\n",
      "iter=540\tepsilon=0.114\treward/step=2.49427\n",
      "iter=550\tepsilon=0.111\treward/step=2.67169\n",
      "iter=560\tepsilon=0.108\treward/step=2.90285\n",
      "iter=570\tepsilon=0.105\treward/step=3.10473\n",
      "iter=580\tepsilon=0.102\treward/step=3.28399\n",
      "iter=590\tepsilon=0.100\treward/step=3.40169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:50:37,748] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:50:37,755] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:50:37,756] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=600\tepsilon=0.097\treward/step=3.50033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:50:38,297] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 10 timesteps with reward=47.0\n",
      "iter=610\tepsilon=0.095\treward/step=3.68085\n",
      "iter=620\tepsilon=0.093\treward/step=3.80370\n",
      "iter=630\tepsilon=0.091\treward/step=3.97369\n",
      "iter=640\tepsilon=0.089\treward/step=4.08830\n",
      "iter=650\tepsilon=0.087\treward/step=4.19831\n",
      "iter=660\tepsilon=0.085\treward/step=4.38744\n",
      "iter=670\tepsilon=0.083\treward/step=4.52280\n",
      "iter=680\tepsilon=0.082\treward/step=4.60764\n",
      "iter=690\tepsilon=0.080\treward/step=4.70521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:51:26,007] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:51:26,017] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:51:26,019] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=700\tepsilon=0.079\treward/step=4.84608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:51:26,363] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1 timesteps with reward=96.0\n",
      "iter=710\tepsilon=0.077\treward/step=4.93755\n",
      "iter=720\tepsilon=0.076\treward/step=5.07073\n",
      "iter=730\tepsilon=0.075\treward/step=5.17045\n",
      "iter=740\tepsilon=0.073\treward/step=5.28124\n",
      "iter=750\tepsilon=0.072\treward/step=5.37630\n",
      "iter=760\tepsilon=0.071\treward/step=5.51051\n",
      "iter=770\tepsilon=0.070\treward/step=5.55875\n",
      "iter=780\tepsilon=0.069\treward/step=5.71319\n",
      "iter=790\tepsilon=0.068\treward/step=5.83869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:52:16,111] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:52:16,120] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:52:16,121] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=800\tepsilon=0.067\treward/step=5.92135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:52:16,546] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 2 timesteps with reward=91.0\n",
      "iter=810\tepsilon=0.067\treward/step=5.99988\n",
      "iter=820\tepsilon=0.066\treward/step=6.07856\n",
      "iter=830\tepsilon=0.065\treward/step=6.20578\n",
      "iter=840\tepsilon=0.064\treward/step=6.26754\n",
      "iter=850\tepsilon=0.064\treward/step=6.32785\n",
      "iter=860\tepsilon=0.063\treward/step=6.41022\n",
      "iter=870\tepsilon=0.062\treward/step=6.46636\n",
      "iter=880\tepsilon=0.062\treward/step=6.53496\n",
      "iter=890\tepsilon=0.061\treward/step=6.57677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:53:11,663] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:53:11,673] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:53:11,675] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=900\tepsilon=0.061\treward/step=6.66337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:53:12,086] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 3 timesteps with reward=86.0\n",
      "iter=910\tepsilon=0.060\treward/step=6.70274\n",
      "iter=920\tepsilon=0.060\treward/step=6.77676\n",
      "iter=930\tepsilon=0.059\treward/step=6.81364\n",
      "iter=940\tepsilon=0.059\treward/step=6.89671\n",
      "iter=950\tepsilon=0.058\treward/step=6.91977\n",
      "iter=960\tepsilon=0.058\treward/step=6.97680\n",
      "iter=970\tepsilon=0.057\treward/step=7.05510\n",
      "iter=980\tepsilon=0.057\treward/step=7.10979\n",
      "iter=990\tepsilon=0.057\treward/step=7.15136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:54:10,651] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:54:10,660] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:54:10,662] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1000\tepsilon=0.056\treward/step=7.21630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:54:11,034] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1 timesteps with reward=96.0\n",
      "iter=1010\tepsilon=0.056\treward/step=7.37120\n",
      "iter=1020\tepsilon=0.056\treward/step=7.53660\n",
      "iter=1030\tepsilon=0.056\treward/step=7.69130\n",
      "iter=1040\tepsilon=0.055\treward/step=7.83840\n",
      "iter=1050\tepsilon=0.055\treward/step=8.02660\n",
      "iter=1060\tepsilon=0.055\treward/step=8.18230\n",
      "iter=1070\tepsilon=0.055\treward/step=8.35640\n",
      "iter=1080\tepsilon=0.054\treward/step=8.52270\n",
      "iter=1090\tepsilon=0.054\treward/step=8.70090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:55:12,218] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:55:12,229] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:55:12,230] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1100\tepsilon=0.054\treward/step=8.90580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:55:12,769] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 8 timesteps with reward=57.0\n",
      "iter=1110\tepsilon=0.054\treward/step=9.09350\n",
      "iter=1120\tepsilon=0.054\treward/step=9.27010\n",
      "iter=1130\tepsilon=0.053\treward/step=9.43460\n",
      "iter=1140\tepsilon=0.053\treward/step=9.57660\n",
      "iter=1150\tepsilon=0.053\treward/step=9.77290\n",
      "iter=1160\tepsilon=0.053\treward/step=9.97880\n",
      "iter=1170\tepsilon=0.053\treward/step=10.14580\n",
      "iter=1180\tepsilon=0.053\treward/step=10.24710\n",
      "iter=1190\tepsilon=0.052\treward/step=10.38830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:56:12,903] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:56:12,914] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:56:12,915] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1200\tepsilon=0.052\treward/step=10.53260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:56:13,349] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 4 timesteps with reward=81.0\n",
      "iter=1210\tepsilon=0.052\treward/step=10.73800\n",
      "iter=1220\tepsilon=0.052\treward/step=10.91160\n",
      "iter=1230\tepsilon=0.052\treward/step=11.06550\n",
      "iter=1240\tepsilon=0.052\treward/step=11.27390\n",
      "iter=1250\tepsilon=0.052\treward/step=11.43840\n",
      "iter=1260\tepsilon=0.052\treward/step=11.59990\n",
      "iter=1270\tepsilon=0.052\treward/step=11.70990\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-21a6bc092d43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#you may want to increase the number of training iterations per one update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hedgedir/agentnet/agentnet/experiments/openai_gym/pool.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, n_steps, append, max_size, add_last_observation, preprocess)\u001b[0m\n\u001b[1;32m    198\u001b[0m             self.experience_replay.append_sessions(observation_tensor, action_tensor, reward_tensor,\n\u001b[1;32m    199\u001b[0m                                                    \u001b[0mis_alive_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreceding_memory_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                                                    max_pool_size=max_size or self.max_size)\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     def evaluate(self, n_games=1, save_path=\"./records\", use_monitor=True, record_video=True, verbose=True,\n",
      "\u001b[0;32m/home/hedgedir/agentnet/agentnet/environment/session_pool.py\u001b[0m in \u001b[0;36mappend_sessions\u001b[0;34m(self, observation_sequences, action_sequences, reward_seq, is_alive, prev_memories, max_pool_size)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m#load everything into the environmnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_sessions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_alive_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprev_memory_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hedgedir/agentnet/agentnet/environment/session_pool.py\u001b[0m in \u001b[0;36mload_sessions\u001b[0;34m(self, observation_sequences, action_sequences, reward_seq, is_alive, prev_memories)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprev_memories\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mprev_memory_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_memory_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreceding_agent_memories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_memories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0mset_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_memory_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_memory_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     def append_sessions(self, observation_sequences, action_sequences, reward_seq, is_alive=None, prev_memories=None,\n",
      "\u001b[0;32m/home/hedgedir/agentnet/agentnet/utils/shared.py\u001b[0m in \u001b[0;36mset_shared\u001b[0;34m(var, value)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mset_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mval_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "for i in xrange(2000):    \n",
    "    \n",
    "    \n",
    "    #train\n",
    "    pool.update(SEQ_LENGTH,append=True)\n",
    "    \n",
    "    for i in range(1): #you may want to increase the number of training iterations per one update\n",
    "        loss = train_step()\n",
    "    targetnet.load_weights(0.01)\n",
    "    \n",
    "    ##update resolver's epsilon (chance of random action instead of optimal one)\n",
    "    current_epsilon = 0.05 + 0.95*np.exp(-epoch_counter/200.)\n",
    "    action_layer.epsilon.set_value(np.float32(current_epsilon))\n",
    "    \n",
    "    if epoch_counter%10==0:\n",
    "        #average reward per game tick in current experience replay pool\n",
    "        pool_mean_reward = pool.experience_replay.rewards.get_value().mean()\n",
    "        print(\"iter=%i\\tepsilon=%.3f\\treward/step=%.5f\"%(epoch_counter,\n",
    "                                                         current_epsilon,\n",
    "                                                         pool_mean_reward))\n",
    "        \n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%100 ==0:\n",
    "        rewards[epoch_counter] = pool.evaluate(record_video=False)\n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#^--- coffee cup got empty, i got bored >.<"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating results\n",
    " * Here we plot learning curves and sample testimonials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1b5f4129d0>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAFkCAYAAAAdXVDGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b623e5150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(*zip(*sorted(list(rewards.items()),key=lambda p:p[0])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:57:26,613] Making new env: ppaquette/DoomBasic-v0\n",
      "[2017-01-14 11:57:26,628] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-01-14 11:57:26,630] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-01-14 11:57:26,957] Starting new video recorder writing to /home/hedgedir/agentnet/examples/records/openaigym.video.14.2042.video000000.mp4\n",
      "[2017-01-14 11:57:27,319] Starting new video recorder writing to /home/hedgedir/agentnet/examples/records/openaigym.video.14.2042.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 3 timesteps with reward=86.0\n",
      "Episode finished after 2 timesteps with reward=91.0\n",
      "Episode finished after 4 timesteps with reward=81.0\n",
      "Episode finished after 8 timesteps with reward=61.0\n",
      "Episode finished after 4 timesteps with reward=81.0\n",
      "Episode finished after 6 timesteps with reward=71.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:57:28,255] Starting new video recorder writing to /home/hedgedir/agentnet/examples/records/openaigym.video.14.2042.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 6 timesteps with reward=71.0\n",
      "Episode finished after 5 timesteps with reward=76.0\n",
      "Episode finished after 6 timesteps with reward=71.0\n",
      "Episode finished after 5 timesteps with reward=76.0\n",
      "Episode finished after 5 timesteps with reward=76.0\n",
      "Episode finished after 5 timesteps with reward=76.0\n",
      "Episode finished after 3 timesteps with reward=86.0\n",
      "Episode finished after 8 timesteps with reward=61.0\n",
      "Episode finished after 4 timesteps with reward=81.0\n",
      "Episode finished after 3 timesteps with reward=86.0\n",
      "Episode finished after 1 timesteps with reward=96.0\n",
      "Episode finished after 5 timesteps with reward=76.0\n",
      "Episode finished after 11 timesteps with reward=38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-14 11:57:29,840] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/hedgedir/agentnet/examples/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 7 timesteps with reward=66.0\n",
      "mean session score=75.350000.5\n"
     ]
    }
   ],
   "source": [
    "action_layer.epsilon.set_value(0.001)\n",
    "rw = pool.evaluate(n_games=20,save_path=\"./records\",record_video=True)\n",
    "print(\"mean session score=%f.5\"%np.mean(rw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.utils.persistence import save,load\n",
    "#save for display\n",
    "save(action_layer,\"doombasic_dqn_2500.pcl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./records/openaigym.video.14.2042.video000008.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import os\n",
    "from random import choice\n",
    "#select the one you want\n",
    "videos = filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\"))\n",
    "video_path=\"./records/\"+choice(videos)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Once you got it working,\n",
    "Try building a network that maximizes the final score\n",
    "\n",
    "* Moar lasagne stuff: convolutional layers, batch normalization, nonlinearities and so on\n",
    "* Recurrent agent memory layers, GRUMemoryLayer, etc\n",
    "* Different reinforcement learning algorithm (p.e. qlearning_n_step), other parameters\n",
    "* Experience replay pool\n",
    "\n",
    "\n",
    "Look for info?\n",
    "* [lasagne doc](http://lasagne.readthedocs.io/en/latest/)\n",
    "* [agentnet doc](http://agentnet.readthedocs.io/en/latest/)\n",
    "* [gym homepage](http://gym.openai.com/)\n",
    "\n",
    "\n",
    "You can also try to expand to a different game: \n",
    " * all OpenAI Atari games are already compatible, you only need to change GAME_TITLE\n",
    " * Other discrete action space environments are also accessible this way\n",
    " * For continuous action spaces, either discretize actions or use continuous RL algorithms (e.g. .learning.dpg_n_step)\n",
    " * Adapting to a custom non-OpenAI environment can be done with a simple wrapper\n",
    " \n",
    " \n",
    "__Good luck!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
